{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_HW7_Seminar_Majid_Sohrabi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d64ff3da313413cbd7dce8c9d5e9fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1797dc5c7b6d405eafa2e62860a17cc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d44f8a0ce08044299e9d731fb81e9d1d",
              "IPY_MODEL_2f2660622a9c461eabca1f5e67d86134",
              "IPY_MODEL_173b8d6675c24dd1b02cffbb2d6a302e"
            ]
          }
        },
        "1797dc5c7b6d405eafa2e62860a17cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d44f8a0ce08044299e9d731fb81e9d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dab9550634074387a9ef3764b7be49ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Batches: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e6fb621b50346c28b915c3d6d1b6644"
          }
        },
        "2f2660622a9c461eabca1f5e67d86134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97ddab4fa29e413b92810a0760eb1b66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16790,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16790,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b804936a5ba84e2195e36eb816e4fc91"
          }
        },
        "173b8d6675c24dd1b02cffbb2d6a302e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50690bddb88f4fb2b9f6e23b027b0551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16790/16790 [05:25&lt;00:00, 80.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0c33ef66c94e83953d901ec9a0ebe5"
          }
        },
        "dab9550634074387a9ef3764b7be49ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e6fb621b50346c28b915c3d6d1b6644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97ddab4fa29e413b92810a0760eb1b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b804936a5ba84e2195e36eb816e4fc91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50690bddb88f4fb2b9f6e23b027b0551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0c33ef66c94e83953d901ec9a0ebe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zriTdjauH8iQ"
      },
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQiRPWWHlSgv"
      },
      "source": [
        "### Using pre-trained transformers (2pts)\n",
        "_for fun and profit_\n",
        "\n",
        "There are many toolkits that let you access pre-trained transformer models, but the most powerful and convenient by far is [`huggingface/transformers`](https://github.com/huggingface/transformers). In this week's practice, you'll learn how to download, apply and modify pre-trained transformers for a range of tasks. Buckle up, we're going in!\n",
        "\n",
        "\n",
        "__Pipelines:__ if all you want is to apply a pre-trained model, you can do that in one line of code using pipeline. Huggingface/transformers has a selection of pre-configured pipelines for masked language modelling, sentiment classification, question aswering, etc. ([see full list here](https://huggingface.co/transformers/main_classes/pipelines.html))\n",
        "\n",
        "A typical pipeline includes:\n",
        "* pre-processing, e.g. tokenization, subword segmentation\n",
        "* a backbone model, e.g. bert finetuned for classification\n",
        "* output post-processing\n",
        "\n",
        "Let's see it in action:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP1KFtvLlJHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468e8577-ee48-49e8-861f-6a1702f282d5"
      },
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis', model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "print(classifier(\"BERT is amazing!\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998860359191895}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYUNuyXMn5l9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da233df-0da4-4625-d191-ece8630fbb62"
      },
      "source": [
        "import base64\n",
        "data = {\n",
        "    'arryn': 'As High as Honor.',\n",
        "    'baratheon': 'Ours is the fury.',\n",
        "    'stark': 'Winter is coming.',\n",
        "    'tyrell': 'Growing strong.'\n",
        "}\n",
        "\n",
        "# YOUR CODE: predict sentiment for each noble house and create outputs dict\n",
        "outputs = {key: True if classifier(val)[0]['label']=='POSITIVE' else False for key, val in data.items()}\n",
        "\n",
        "assert sum(outputs.values()) == 3 and outputs[base64.decodestring(b'YmFyYXRoZW9u\\n').decode()] == False\n",
        "print(\"Well done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: decodestring() is a deprecated alias since Python 3.1, use decodebytes()\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRDhIH-XpSNo"
      },
      "source": [
        "You can also access vanilla Masked Language Model that was trained to predict masked words. Here's how:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa-8noIllRbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069b5563-42d3-400f-a4f3-06abc46b095e"
      },
      "source": [
        "mlm_model = pipeline('fill-mask', model=\"bert-base-uncased\")\n",
        "MASK = mlm_model.tokenizer.mask_token\n",
        "\n",
        "for hypo in mlm_model(f\"Donald {MASK} is the president of the united states.\"):\n",
        "  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P=0.99719 donald trump is the president of the united states.\n",
            "P=0.00024 donald duck is the president of the united states.\n",
            "P=0.00022 donald ross is the president of the united states.\n",
            "P=0.00020 donald johnson is the president of the united states.\n",
            "P=0.00018 donald wilson is the president of the united states.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NxeG1Y5pwX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e251a2-e50d-4d71-a548-114e70194aab"
      },
      "source": [
        "# Your turn: use bert to recall what year was the Soviet Union founded in\n",
        "mlm_model(f'Soviet Union founded in year {MASK}.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.019652394577860832,\n",
              "  'sequence': 'soviet union founded in year 1945.',\n",
              "  'token': 3386,\n",
              "  'token_str': '1945'},\n",
              " {'score': 0.018977005034685135,\n",
              "  'sequence': 'soviet union founded in year 1947.',\n",
              "  'token': 4006,\n",
              "  'token_str': '1947'},\n",
              " {'score': 0.017779849469661713,\n",
              "  'sequence': 'soviet union founded in year 1917.',\n",
              "  'token': 4585,\n",
              "  'token_str': '1917'},\n",
              " {'score': 0.012720368802547455,\n",
              "  'sequence': 'soviet union founded in year 1949.',\n",
              "  'token': 4085,\n",
              "  'token_str': '1949'},\n",
              " {'score': 0.012019014917314053,\n",
              "  'sequence': 'soviet union founded in year 1948.',\n",
              "  'token': 3882,\n",
              "  'token_str': '1948'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJxRFzCSq903"
      },
      "source": [
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "Huggingface offers hundreds of pre-trained models that specialize on different tasks. You can quickly find the model you need using [this list](https://huggingface.co/models).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRux8Qp2hkXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007c24c2-64fc-4172-fa4b-c38c7d0f6e56"
      },
      "source": [
        "text = \"\"\"Almost two-thirds of the 1.5 million people who viewed this liveblog had Googled to discover\n",
        " the latest on the Rosetta mission. They were treated to this detailed account by the Guardian’s science editor,\n",
        " Ian Sample, and astronomy writer Stuart Clark of the moment scientists landed a robotic spacecraft on a comet \n",
        " for the first time in history, and the delirious reaction it provoked at their headquarters in Germany.\n",
        "  “We are there. We are sitting on the surface. Philae is talking to us,” said one scientist.\n",
        "\"\"\"\n",
        "\n",
        "# Task: create a pipeline for named entity recognition, use task name 'ner' and search for the right model in the list\n",
        "ner_model = pipeline('ner')\n",
        "\n",
        "named_entities = ner_model(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf57MRzSiSON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790e57ca-80b3-42b1-a40e-adb03b32ac8e"
      },
      "source": [
        "print('OUTPUT:', named_entities)\n",
        "word_to_entity = {item['word']: item['entity'] for item in named_entities}\n",
        "assert 'org' in word_to_entity.get('Guardian').lower() and 'per' in word_to_entity.get('Stuart').lower()\n",
        "print(\"All tests passed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUT: [{'entity': 'I-MISC', 'score': 0.88031083, 'index': 19, 'word': 'Google', 'start': 73, 'end': 79}, {'entity': 'I-MISC', 'score': 0.9005079, 'index': 27, 'word': 'Rose', 'start': 112, 'end': 116}, {'entity': 'I-MISC', 'score': 0.95096296, 'index': 28, 'word': '##tta', 'start': 116, 'end': 119}, {'entity': 'I-ORG', 'score': 0.99925345, 'index': 40, 'word': 'Guardian', 'start': 179, 'end': 187}, {'entity': 'I-PER', 'score': 0.99920094, 'index': 46, 'word': 'Ian', 'start': 207, 'end': 210}, {'entity': 'I-PER', 'score': 0.99950004, 'index': 47, 'word': 'Sam', 'start': 211, 'end': 214}, {'entity': 'I-PER', 'score': 0.99649787, 'index': 48, 'word': '##ple', 'start': 214, 'end': 217}, {'entity': 'I-PER', 'score': 0.9991856, 'index': 53, 'word': 'Stuart', 'start': 240, 'end': 246}, {'entity': 'I-PER', 'score': 0.9996484, 'index': 54, 'word': 'Clark', 'start': 247, 'end': 252}, {'entity': 'I-LOC', 'score': 0.99982107, 'index': 85, 'word': 'Germany', 'start': 414, 'end': 421}, {'entity': 'I-PER', 'score': 0.62956923, 'index': 99, 'word': 'Phil', 'start': 471, 'end': 475}, {'entity': 'I-PER', 'score': 0.8340381, 'index': 100, 'word': '##ae', 'start': 475, 'end': 477}]\n",
            "All tests passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULMownz6sP9n"
      },
      "source": [
        "### The building blocks of a pipeline\n",
        "\n",
        "Huggingface also allows you to access its pipelines on a lower level. There are two main abstractions for you:\n",
        "* `Tokenizer` - converts from strings to token ids and back\n",
        "* `Model` - a pytorch `nn.Module` with pre-trained weights\n",
        "\n",
        "You can use such models as part of your regular pytorch code: insert is as a layer in your model, apply it to a batch of data, backpropagate, optimize, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMJbV0QVsO0Q"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgSPHKPRxG6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad7301a-f406-44d1-98b9-8238fd9d7d70"
      },
      "source": [
        "lines = [\n",
        "    \"Luke, I am your father.\",\n",
        "    \"Life is what happens when you're busy making other plans.\",\n",
        "    ]\n",
        "\n",
        "# tokenize a batch of inputs. \"pt\" means [p]y[t]orch tensors\n",
        "tokens_info = tokenizer(lines, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "for key in tokens_info:\n",
        "    print(key, tokens_info[key])\n",
        "\n",
        "print(\"Detokenized:\")\n",
        "for i in range(2):\n",
        "    print(tokenizer.decode(tokens_info['input_ids'][i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids tensor([[ 101, 5355, 1010, 1045, 2572, 2115, 2269, 1012,  102,    0,    0,    0,\n",
            "            0,    0,    0],\n",
            "        [ 101, 2166, 2003, 2054, 6433, 2043, 2017, 1005, 2128, 5697, 2437, 2060,\n",
            "         3488, 1012,  102]])\n",
            "token_type_ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "Detokenized:\n",
            "[CLS] luke, i am your father. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] life is what happens when you're busy making other plans. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJkbHxERyfL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e5266c-3b60-48bd-e654-98b04e9656ec"
      },
      "source": [
        "# You can now apply the model to get embeddings\n",
        "with torch.no_grad():\n",
        "    out = model(**tokens_info)\n",
        "\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.3502,  0.2246, -0.2345,  ..., -0.2232,  0.1730,  0.6747],\n",
            "         [-0.6097,  0.6892, -0.5512,  ..., -0.4814,  0.5322,  1.3833],\n",
            "         [ 0.1842,  0.4881,  0.2193,  ..., -0.2699,  0.2246,  0.7985],\n",
            "         ...,\n",
            "         [-0.4413,  0.2748, -0.0391,  ..., -0.0604, -0.4358,  0.1384],\n",
            "         [-0.5414,  0.4633,  0.0678,  ..., -0.1871, -0.5046,  0.2752],\n",
            "         [-0.3940,  0.6180,  0.2092,  ..., -0.2345, -0.4177,  0.3341]],\n",
            "\n",
            "        [[ 0.1622, -0.1154, -0.3894,  ..., -0.4180,  0.0138,  0.7644],\n",
            "         [ 0.6471,  0.3774, -0.4082,  ...,  0.0050,  0.5559,  0.4385],\n",
            "         [ 0.3351, -0.3158, -0.1178,  ...,  0.1348, -0.3143,  1.4409],\n",
            "         ...,\n",
            "         [ 1.2932, -0.1743, -0.5613,  ..., -0.2718, -0.1367,  0.4217],\n",
            "         [ 1.0304,  0.1708, -0.2985,  ...,  0.2097, -0.4627, -0.4277],\n",
            "         [ 1.0854,  0.1760, -0.0377,  ...,  0.3152, -0.5979, -0.3465]]]), pooler_output=tensor([[-0.8854, -0.4722, -0.9392,  ..., -0.8081, -0.6955,  0.8748],\n",
            "        [-0.9297, -0.5161, -0.9334,  ..., -0.9017, -0.7492,  0.9201]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49wJnZHJsP7Y"
      },
      "source": [
        "### Fine-tuning for salary prediction (5 pts)\n",
        "\n",
        "Now let's put all this monstrosity to good use!\n",
        "\n",
        "Remember week5 when you've trained a convolutional neural network for salary prediction? Now let's see how transformers fare at this task.\n",
        "\n",
        "__The goal__ is to take one or more pre-trained models and fine-tune it for salary prediction. A good baseline solution would be to get RoBerta or T5 from [huggingface model list](https://huggingface.co/models) and fine-tune it to solve the task. After choosing the model, please take care to use the matching Tokenizer for preprocessing, as different models have different preprocessing requirements.\n",
        "\n",
        "\n",
        "There are no prompts this time: you will have to write everything from scratch. Although, feel free to reuse any code from the original salary prediction notebook :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMGQ-I3asP7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb2948e-24e5-415f-c99e-fe779500cc2c"
      },
      "source": [
        "!wget https://www.dropbox.com/s/r9d1f3ve471osob/Train_rev1.zip?dl=1 -O data.zip\n",
        "!unzip -e data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-12 14:59:32--  https://www.dropbox.com/s/r9d1f3ve471osob/Train_rev1.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/r9d1f3ve471osob/Train_rev1.zip [following]\n",
            "--2021-11-12 14:59:33--  https://www.dropbox.com/s/dl/r9d1f3ve471osob/Train_rev1.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc95a52af866e07fb6483bd424fb.dl.dropboxusercontent.com/cd/0/get/BZ01S9BaosfoWUzuAb_YoqMrZYNsvCj6if06ykT_LvfVJB0-gh5-qtFol917QOTIW5Rp0dW0TXGcUnYuapZRaG0PZCR6Oz_wZp42ArQyIhbujxZZgCT7L5buO45eLNBJQNEcWFZ_RClRdR8qC7XAwWPf/file?dl=1# [following]\n",
            "--2021-11-12 14:59:33--  https://uc95a52af866e07fb6483bd424fb.dl.dropboxusercontent.com/cd/0/get/BZ01S9BaosfoWUzuAb_YoqMrZYNsvCj6if06ykT_LvfVJB0-gh5-qtFol917QOTIW5Rp0dW0TXGcUnYuapZRaG0PZCR6Oz_wZp42ArQyIhbujxZZgCT7L5buO45eLNBJQNEcWFZ_RClRdR8qC7XAwWPf/file?dl=1\n",
            "Resolving uc95a52af866e07fb6483bd424fb.dl.dropboxusercontent.com (uc95a52af866e07fb6483bd424fb.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc95a52af866e07fb6483bd424fb.dl.dropboxusercontent.com (uc95a52af866e07fb6483bd424fb.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128356352 (122M) [application/binary]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 122.41M  15.0MB/s    in 9.0s    \n",
            "\n",
            "2021-11-12 14:59:43 (13.7 MB/s) - ‘data.zip’ saved [128356352/128356352]\n",
            "\n",
            "Archive:  data.zip\n",
            "  inflating: Train_rev1.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dPhfXV-K6S-D",
        "outputId": "624e1619-0f32-4b12-d3f5-2e4c9149805e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)\n",
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "\n",
        "\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast nan to string\n",
        "\n",
        "data.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>Log1pSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61407</th>\n",
              "      <td>68696057</td>\n",
              "      <td>Compensation and Benefits Advisor</td>\n",
              "      <td>A multinational Oil Gas company is looking for...</td>\n",
              "      <td>City London South East</td>\n",
              "      <td>London</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Badenoch &amp; Clark   London</td>\n",
              "      <td>HR &amp; Recruitment Jobs</td>\n",
              "      <td>40000 - 60000 per annum</td>\n",
              "      <td>50000</td>\n",
              "      <td>totaljobs.com</td>\n",
              "      <td>10.819798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129620</th>\n",
              "      <td>70149683</td>\n",
              "      <td>NQT wanted in Darlington</td>\n",
              "      <td>If you are an NQT and would be interested in l...</td>\n",
              "      <td>Darlington</td>\n",
              "      <td>Darlington</td>\n",
              "      <td>full_time</td>\n",
              "      <td>contract</td>\n",
              "      <td>Capita Education</td>\n",
              "      <td>Teaching Jobs</td>\n",
              "      <td>80.50 - 90.50 per day</td>\n",
              "      <td>20520</td>\n",
              "      <td>jobs.newstatesman.com</td>\n",
              "      <td>9.929204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6075</th>\n",
              "      <td>62120474</td>\n",
              "      <td>Financial Planning and Analysis Manager</td>\n",
              "      <td>My client an innovative telecoms provider requ...</td>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "      <td>full_time</td>\n",
              "      <td>permanent</td>\n",
              "      <td>CMC Consulting</td>\n",
              "      <td>Accounting &amp; Finance Jobs</td>\n",
              "      <td>From 60,000 to 60,000 per year</td>\n",
              "      <td>60000</td>\n",
              "      <td>fish4.co.uk</td>\n",
              "      <td>11.002116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Id  ... Log1pSalary\n",
              "61407   68696057  ...   10.819798\n",
              "129620  70149683  ...    9.929204\n",
              "6075    62120474  ...   11.002116\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "m9fkVvr16S4p",
        "outputId": "e20202fc-4083-43ca-f274-7d90a6051b4a"
      },
      "source": [
        "plt.hist(data['Log1pSalary'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  714.,  1138., 18622., 42467., 68697., 65041., 33935., 12601.,\n",
              "         1444.,   109.]),\n",
              " array([ 8.517393 ,  8.886262 ,  9.25513  ,  9.623999 ,  9.9928665,\n",
              "        10.361735 , 10.730604 , 11.099472 , 11.468341 , 11.837209 ,\n",
              "        12.206078 ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDnkwou_JneV",
        "outputId": "07953312-71e2-4e6e-fab9-d70e6a50501d"
      },
      "source": [
        "print(\"Before\")\n",
        "print(data[\"Title\"][::100000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before\n",
            "0         Engineering Systems Analyst\n",
            "100000                   HR Assistant\n",
            "200000           Senior EC&I Engineer\n",
            "Name: Title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVGPcuSDJnbG"
      },
      "source": [
        "import nltk\n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "\n",
        "for col in text_columns:\n",
        "    data[col] = data[col].apply(lambda l: ' '.join(tokenizer.tokenize(str(l).lower())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgaA4QQGJ4MF",
        "outputId": "99281982-f0d4-4685-c0d8-4bce73f1bc99"
      },
      "source": [
        "print(\"After\")\n",
        "print(data[\"Title\"][::100000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After\n",
            "0         engineering systems analyst\n",
            "100000                   hr assistant\n",
            "200000         senior ec & i engineer\n",
            "Name: Title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxCYjsb9J4JR",
        "outputId": "ba12edf0-113d-444d-a177-bd0e1e826950"
      },
      "source": [
        "data['Title'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['engineering systems analyst', 'stress engineer glasgow',\n",
              "       'modelling and simulation analyst', ..., 'english teacher',\n",
              "       'supply teachers', 'accountant'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQtJZZUzJnVi"
      },
      "source": [
        "from collections import Counter\n",
        "token_counts = Counter()\n",
        "\n",
        "# Count how many times does each token occur in \"Title\" and \"FullDescription\"\n",
        "for row in data['FullDescription'].values:\n",
        "  token_counts.update(row.split())\n",
        "\n",
        "for row in data['Title'].values:\n",
        "  token_counts.update(row.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBtLsRejKYJY",
        "outputId": "59514152-8feb-49fd-8495-6f92d0ac60ed"
      },
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 202704\n",
            "('and', 2657388)\n",
            "('.', 2523216)\n",
            "(',', 2318606)\n",
            "('the', 2080994)\n",
            "('to', 2019884)\n",
            "...\n",
            "('improvemen', 1)\n",
            "('techniciancivil', 1)\n",
            "('mlnlycke', 1)\n",
            "Correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "J2p6W0oqKYGk",
        "outputId": "b314862e-4b8d-424c-e130-356af128d798"
      },
      "source": [
        "# Let's see how many words are there for each count\n",
        "\n",
        "_=plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
        "plt.xlabel(\"Counts\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Counts')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjzoB6tAKYEk"
      },
      "source": [
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]\n",
        "\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSjzjzmKKYCS",
        "outputId": "617fae60-eee5-4d32-ffe7-f46a378d5245"
      },
      "source": [
        "print(\"Tokens left:\", len(tokens))\n",
        "assert type(tokens)==list\n",
        "assert len(tokens) in range(32000,35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens left: 34158\n",
            "Correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7pKZrWZKYAA"
      },
      "source": [
        "token_to_id = dict()\n",
        "for i, word in enumerate(tokens):\n",
        "  token_to_id[word] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "784PlGKQMI3t",
        "outputId": "bd087893-78ee-470b-8999-82e20f8699ac"
      },
      "source": [
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz0flJWiMI02"
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1lpq7sGMIys",
        "outputId": "58e65dcf-7f71-434a-bbe0-0590cfca78f1"
      },
      "source": [
        "#### print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[    2     3     4     1     1]\n",
            " [  548  2361     1     1     1]\n",
            " [  537 10662   390   307    32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE8_s0-VOceC",
        "outputId": "caf940b2-c3d4-4431-a202-e89506ad74fb"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
              "               sparse=False)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqQVBBhqOcbO",
        "outputId": "f5e690c8-942c-48c1-a711-fdcf6813d48f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  220291\n",
            "Validation size =  24477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GxZt95-OcZP"
      },
      "source": [
        "def generate_batch(data, batch_size=None, replace=True, max_len=None):\n",
        "    \"\"\"\n",
        "    Creates a pytorch-friendly dict from the batch data.\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    if batch_size is not None:\n",
        "        data = data.sample(batch_size, replace=replace)\n",
        "    \n",
        "    batch = {}\n",
        "    for col in text_columns:\n",
        "        batch[col] = as_matrix(data[col].values, max_len)\n",
        "    \n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YMwwVX_OcXD",
        "outputId": "8a2ef305-bc9b-43f3-a36a-d68edd456ae2"
      },
      "source": [
        "generate_batch(data_train, 3, max_len=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'FullDescription': array([[   48,  1982,  1535,   183,   230,    66,   188,  2322,    19,\n",
              "           183],\n",
              "        [  299,   691,   104,   120, 19048,   812,  5823,  4098, 14315,\n",
              "          1098],\n",
              "        [   17,    65, 26537,   819, 17727,   414,    35,    17,    49,\n",
              "           101]], dtype=int32),\n",
              " 'Log1pSalary': array([10.308986, 10.307585, 10.021315], dtype=float32),\n",
              " 'Title': array([[ 1982,  1535,   712,    96, 18034],\n",
              "        [  565,  2807,  2822,     1,     1],\n",
              "        [  937,   896,     1,     1,     1]], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_UUvLMquyp"
      },
      "source": [
        "pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps4NLjl8MIwc"
      },
      "source": [
        "from datasets import list_datasets, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') #roberta-base\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased') #bert-base-uncased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NmT1PyaMIuH"
      },
      "source": [
        "import torch\n",
        "device = 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPKRVNH-b-bn"
      },
      "source": [
        "my_data_train = data_train.drop(['SalaryNormalized'], axis=1)\n",
        "my_data_val = data_val.drop(['SalaryNormalized'], axis=1)\n",
        "\n",
        "X_train_datset = Dataset.from_pandas(my_data_train)\n",
        "X_val_dataset = Dataset.from_pandas(my_data_val)\n",
        "\n",
        "X_train_datset.remove_columns_(['__index_level_0__'])\n",
        "X_val_dataset.remove_columns_(['__index_level_0__'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKHIYXoRT3xI"
      },
      "source": [
        "X_train_tokenized = tokenizer(X_train_datset[\"FullDescription\"],X_train_datset[\"Title\"],X_train_datset[\"Category\"], padding=True, truncation=True, return_tensors=\"pt\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5j-A3IMT3ps"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMpzCoIL0Mmw"
      },
      "source": [
        "### The search for similar questions (3pts)\n",
        "\n",
        "* Implement a function that takes a text string and finds top-k most similar questions from `quora.txt`\n",
        "* Demonstrate your function using at least 5 examples\n",
        "\n",
        "There are no prompts this time: you will have to write everything from scratch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLqtAcD3CXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a60e36-31fa-441b-ba05-f057a41537c3"
      },
      "source": [
        "# download the data:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-13 17:24:28--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/obaitrix9jyu84r/quora.txt [following]\n",
            "--2021-11-13 17:24:28--  https://www.dropbox.com/s/dl/obaitrix9jyu84r/quora.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucca58c8fc3942a7071373efc2c2.dl.dropboxusercontent.com/cd/0/get/BZ5li9umruk_xiwkhIYJ2a1uVES1xozFes-tf-Dya5aXpUFir5j-m-u571Ahrvd3eVZp2IvRLVeYVdXohwcRk1bxt4jGbJ1HxDSpo_DCqoFydiUAwCu7rh1oRv-o-Depb7ThXT7RnKM7Wxl_o3vXNGHT/file?dl=1# [following]\n",
            "--2021-11-13 17:24:28--  https://ucca58c8fc3942a7071373efc2c2.dl.dropboxusercontent.com/cd/0/get/BZ5li9umruk_xiwkhIYJ2a1uVES1xozFes-tf-Dya5aXpUFir5j-m-u571Ahrvd3eVZp2IvRLVeYVdXohwcRk1bxt4jGbJ1HxDSpo_DCqoFydiUAwCu7rh1oRv-o-Depb7ThXT7RnKM7Wxl_o3vXNGHT/file?dl=1\n",
            "Resolving ucca58c8fc3942a7071373efc2c2.dl.dropboxusercontent.com (ucca58c8fc3942a7071373efc2c2.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucca58c8fc3942a7071373efc2c2.dl.dropboxusercontent.com (ucca58c8fc3942a7071373efc2c2.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33813903 (32M) [application/binary]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt         100%[===================>]  32.25M  33.6MB/s    in 1.0s    \n",
            "\n",
            "2021-11-13 17:24:30 (33.6 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy_Gy7b2Vsi-"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsr4Jr0gzPvf"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXt_Ma1fVLIS"
      },
      "source": [
        "mySent_list = []\n",
        "with open(\"quora.txt\", \"r\") as f:\n",
        "  for i in f:\n",
        "    mySent_list.append(i.strip(\"\\n\"))\n",
        "\n",
        "my_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1d64ff3da313413cbd7dce8c9d5e9fb7",
            "1797dc5c7b6d405eafa2e62860a17cc7",
            "d44f8a0ce08044299e9d731fb81e9d1d",
            "2f2660622a9c461eabca1f5e67d86134",
            "173b8d6675c24dd1b02cffbb2d6a302e",
            "dab9550634074387a9ef3764b7be49ac",
            "7e6fb621b50346c28b915c3d6d1b6644",
            "97ddab4fa29e413b92810a0760eb1b66",
            "b804936a5ba84e2195e36eb816e4fc91",
            "50690bddb88f4fb2b9f6e23b027b0551",
            "2d0c33ef66c94e83953d901ec9a0ebe5"
          ]
        },
        "id": "wouQpmD5VLGI",
        "outputId": "707bfcff-3263-4896-a9f7-ade98c1261cb"
      },
      "source": [
        "corpus_embeddings = my_model.encode(mySent_list, convert_to_tensor=True, show_progress_bar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d64ff3da313413cbd7dce8c9d5e9fb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/16790 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt0jOFmuVLD0"
      },
      "source": [
        "queries = mySent_list[-5:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq1EJMdGVLBe",
        "outputId": "ef5ce7d5-1705-4fe7-f037-a15cdf3a1648"
      },
      "source": [
        "queries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What are some facts about the various Vice Presidents of India?',\n",
              " 'What are some suggestions for a project in mechanical engineering for design engineering subject?',\n",
              " 'Is it necessary to do a diploma in nautical science before joining IMU?',\n",
              " 'Can you debeak cockerels at 8 months old?',\n",
              " 'What are the most unintentionally hilarious movies you have ever seen?']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFxgEPbfZmSi",
        "outputId": "8335352a-7a0f-431a-e236-065e3c4280af"
      },
      "source": [
        "query_emb = my_model.encode(queries, convert_to_tensor=True)\n",
        "co_scores = util.pytorch_cos_sim(query_emb, corpus_embeddings)[0]\n",
        "co_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1137, -0.0676,  0.2008,  ...,  0.0538, -0.0338,  0.1011],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggI-eeMWZmJv"
      },
      "source": [
        "best_k = min(5, len(mySent_list))\n",
        "best_results = torch.topk(co_scores, k=best_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNVovKVNZmGr",
        "outputId": "e5825f13-e7db-40d4-9a5f-51d55f79ec1f"
      },
      "source": [
        "best_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([1.0000, 0.9810, 0.7507, 0.6983, 0.6838], device='cuda:0'), indices=tensor([537267, 145428, 269465, 220042,  50443], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aolv0njkZmEb",
        "outputId": "f28d4e10-43b4-4de3-d190-12c1fbaac2dc"
      },
      "source": [
        "for val, indx in zip(best_results[0], best_results[1]):\n",
        "  print(f'Score: {val} ==> \"{mySent_list[indx]}\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 1.0000001192092896 ==> \"What are some facts about the various Vice Presidents of India?\"\n",
            "Score: 0.9810048937797546 ==> \"What are some interesting facts about various vice presidents of India?\"\n",
            "Score: 0.7506682872772217 ==> \"What does the Vice President of India do?\"\n",
            "Score: 0.6982877254486084 ==> \"Who is the vice-president of India?\"\n",
            "Score: 0.683841347694397 ==> \"What are some infamous facts about famous Indian politicians?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TstFxxZjbnaw",
        "outputId": "3d5c9887-ed73-4af6-ddc7-dc35e0322ad5"
      },
      "source": [
        "for iter in range(0, 5):\n",
        "  co_scores = util.pytorch_cos_sim(query_emb, corpus_embeddings)[iter]\n",
        "  best_k = min(5, len(mySent_list))\n",
        "  best_results = torch.topk(co_scores, k=best_k)\n",
        "\n",
        "  for val, indx in zip(best_results[0], best_results[1]):\n",
        "    print(f'Score: {val} ==> \"{mySent_list[indx]}\"')\n",
        "  print('\\n\\n $$$$$$$$$$$$$$$$$$$$$$$$$$$$ \\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 1.0000001192092896 ==> \"What are some facts about the various Vice Presidents of India?\"\n",
            "Score: 0.9810048937797546 ==> \"What are some interesting facts about various vice presidents of India?\"\n",
            "Score: 0.7506682872772217 ==> \"What does the Vice President of India do?\"\n",
            "Score: 0.6982877254486084 ==> \"Who is the vice-president of India?\"\n",
            "Score: 0.683841347694397 ==> \"What are some infamous facts about famous Indian politicians?\"\n",
            "\n",
            "\n",
            " $$$$$$$$$$$$$$$$$$$$$$$$$$$$ \n",
            "\n",
            "\n",
            "Score: 1.000000238418579 ==> \"What are some suggestions for a project in mechanical engineering for design engineering subject?\"\n",
            "Score: 0.8952311873435974 ==> \"What are some good project ideas for mechanical engineering?\"\n",
            "Score: 0.856448233127594 ==> \"Can you suggest some projects for mechanical engineering students that includes design and analysis?\"\n",
            "Score: 0.8458020687103271 ==> \"What are some Project ideas for mechanical engineering students?\"\n",
            "Score: 0.8405192494392395 ==> \"What are some mechanical engineering projects?\"\n",
            "\n",
            "\n",
            " $$$$$$$$$$$$$$$$$$$$$$$$$$$$ \n",
            "\n",
            "\n",
            "Score: 1.0 ==> \"Is it necessary to do a diploma in nautical science before joining IMU?\"\n",
            "Score: 0.96902996301651 ==> \"Is Doing Diploma in Nautical science is necessary before joining IMU?\"\n",
            "Score: 0.786145806312561 ==> \"Is BSc. in Nautical Science degree from IMU equivalent to other graduation degree from any college or university?\"\n",
            "Score: 0.7602832913398743 ==> \"How do I join the merchant navy after +2 for a B.Sc & what are the best institutes for completing a B.Sc in nautical science?\"\n",
            "Score: 0.7379668951034546 ==> \"Which course is better Diploma in nautical science or Bsc nautical science?\"\n",
            "\n",
            "\n",
            " $$$$$$$$$$$$$$$$$$$$$$$$$$$$ \n",
            "\n",
            "\n",
            "Score: 1.0000001192092896 ==> \"Can you debeak cockerels at 8 months old?\"\n",
            "Score: 0.6046683192253113 ==> \"How can I get rid of little cockroaches?\"\n",
            "Score: 0.5773102641105652 ==> \"How can I get rid of tiny cockroaches?\"\n",
            "Score: 0.5743383169174194 ==> \"How can I get rid of flying cockroaches?\"\n",
            "Score: 0.5669078826904297 ==> \"How can I get rid of big flying cockroaches?\"\n",
            "\n",
            "\n",
            " $$$$$$$$$$$$$$$$$$$$$$$$$$$$ \n",
            "\n",
            "\n",
            "Score: 0.9999998211860657 ==> \"What are the most unintentionally hilarious movies you have ever seen?\"\n",
            "Score: 0.855338990688324 ==> \"What is the most unintentionally hilarious horror movie you've ever seen?\"\n",
            "Score: 0.8298603296279907 ==> \"What are some of the most amazing unheard of movies you have ever watched?\"\n",
            "Score: 0.792526125907898 ==> \"What are the most ridiculous movies you have ever seen?\"\n",
            "Score: 0.7529536485671997 ==> \"What is the most funny movie you have watched?\"\n",
            "\n",
            "\n",
            " $$$$$$$$$$$$$$$$$$$$$$$$$$$$ \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHEC6o7uAfgQ"
      },
      "source": [
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "__Bonus demo:__ transformer language models. \n",
        "\n",
        "`/* No points awarded for this task, but its really cool, we promise :) */`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWCajBGcAern"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2').train(False).to(device)\n",
        "\n",
        "text = \"The Fermi paradox \"\n",
        "tokens = tokenizer.encode(text)\n",
        "num_steps = 1024\n",
        "line_length, max_length = 0, 70\n",
        "\n",
        "print(end=tokenizer.decode(tokens))\n",
        "\n",
        "for i in range(num_steps):\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.as_tensor([tokens], device=device))[0]\n",
        "    p_next = torch.softmax(logits[0, -1, :], dim=-1).data.cpu().numpy()\n",
        "\n",
        "    next_token_index = p_next.argmax() #<YOUR CODE: REPLACE THIS LINE>\n",
        "    # YOUR TASK: change the code so that it performs nucleus sampling\n",
        "\n",
        "    tokens.append(int(next_token_index))\n",
        "    print(end=tokenizer.decode(tokens[-1]))\n",
        "    line_length += len(tokenizer.decode(tokens[-1]))\n",
        "    if line_length >= max_length:\n",
        "        line_length = 0\n",
        "        print()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vij7Gc1wOaq"
      },
      "source": [
        "Transformers knowledge hub: https://huggingface.co/transformers/"
      ]
    }
  ]
}